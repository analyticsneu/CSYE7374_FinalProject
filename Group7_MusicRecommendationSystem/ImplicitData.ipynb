{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(appName=\"Music_Recommendation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/usersha1-artmbid-artname-plays.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17559530"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t3bd73256-3905-4f3a-97e2-8b341527f805\\tbetty blowtorch\\t2137',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\tf2fb0ff0-5679-42ec-a55c-15109ce6e320\\tdie \\xc4rzte\\t1099',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\tb3ae82c2-e60b-4551-a76d-6620f1b456aa\\tmelissa etheridge\\t897',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t3d6bbeb7-f90e-4d10-b440-e153c0d10b53\\telvenking\\t717',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\tbbd2ffd7-17f4-4506-8572-c1ea58c3f9a8\\tjuliette & the licks\\t706',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t8bfac288-ccc5-448d-9573-c33ea2aa5c30\\tred hot chili peppers\\t691',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t6531c8b1-76ea-4141-b270-eb1ac5b41375\\tmagica\\t545',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t21f3573f-10cf-44b3-aeaa-26cccd8448b5\\tthe black dahlia murder\\t507',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\tc5db90c4-580d-4f33-b364-fbaa5a3a58b5\\tthe murmurs\\t424',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b\\t0639533a-0402-40ba-b6e0-18b067198b73\\tlunachicks\\t403']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = data.map(lambda line: line.split(\"\\t\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2],tokens[3])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'3bd73256-3905-4f3a-97e2-8b341527f805',\n",
       "  u'betty blowtorch',\n",
       "  u'2137'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'f2fb0ff0-5679-42ec-a55c-15109ce6e320',\n",
       "  u'die \\xc4rzte',\n",
       "  u'1099'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'b3ae82c2-e60b-4551-a76d-6620f1b456aa',\n",
       "  u'melissa etheridge',\n",
       "  u'897'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'3d6bbeb7-f90e-4d10-b440-e153c0d10b53',\n",
       "  u'elvenking',\n",
       "  u'717'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8',\n",
       "  u'juliette & the licks',\n",
       "  u'706'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'8bfac288-ccc5-448d-9573-c33ea2aa5c30',\n",
       "  u'red hot chili peppers',\n",
       "  u'691'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'6531c8b1-76ea-4141-b270-eb1ac5b41375',\n",
       "  u'magica',\n",
       "  u'545'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'21f3573f-10cf-44b3-aeaa-26cccd8448b5',\n",
       "  u'the black dahlia murder',\n",
       "  u'507'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'c5db90c4-580d-4f33-b364-fbaa5a3a58b5',\n",
       "  u'the murmurs',\n",
       "  u'424'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'0639533a-0402-40ba-b6e0-18b067198b73',\n",
       "  u'lunachicks',\n",
       "  u'403')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       " u'00000c289a1829a808ac09c00daf10bc3c4e223b']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17559530"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359349"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = dt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[29] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniq(a):\n",
    "    z=0\n",
    "    for i in s:\n",
    "        if a[0] == i:\n",
    "            a[0]=z\n",
    "            break\n",
    "        z = z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-b7572a2fe78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2d0d61cc03f3abd6c5f86087cc92743d3af4d61c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-95e322a982e3>\u001b[0m in \u001b[0;36muniq\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object is not iterable"
     ]
    }
   ],
   "source": [
    "c = uniq('2d0d61cc03f3abd6c5f86087cc92743d3af4d61c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 1 times, most recent failure: Lost task 0.0 in stage 10.0 (TID 202, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.py\", line 1261, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-30-da8cfc54b404>\", line 4, in unique1\nUnboundLocalError: local variable 'a' referenced before assignment\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:97)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0bd7ea5eb95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/context.pyc\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions,\n\u001b[0;32m--> 881\u001b[0;31m                                           allowLocal)\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 1 times, most recent failure: Lost task 0.0 in stage 10.0 (TID 202, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.py\", line 1261, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-30-da8cfc54b404>\", line 4, in unique1\nUnboundLocalError: local variable 'a' referenced before assignment\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:97)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 256, localhost): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:2271)\n\tat java.io.ByteArrayOutputStream.toByteArray(ByteArrayOutputStream.java:191)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:83)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:236)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-21d87579279a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzipWithUniqueId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \"\"\"\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 256, localhost): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:2271)\n\tat java.io.ByteArrayOutputStream.toByteArray(ByteArrayOutputStream.java:191)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:83)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:236)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n"
     ]
    }
   ],
   "source": [
    "data1.zipWithUniqueId()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = sc.parallelize(range(0,359349))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2d0d61cc03f3abd6c5f86087cc92743d3af4d61c',\n",
       " u'363ca60eef993a994eb383c820df73553bd1f3a6',\n",
       " u'cb16eaaf4b3ab12821a601fddae9bdbd61efddcd',\n",
       " u'8e3099e948736e15fdcfe7db8a957b3878836c65',\n",
       " u'd3d2395652ca7446c2c401411a9c9af28aea9d77',\n",
       " u'0ef59c4e157151d6468cedfa85a68e1a9a8a16dc',\n",
       " u'39166b2f99039eb1eba41c9a5e39ec2b422edaa5',\n",
       " u'40ef4999c8cb743e6c7624b45e8be057d5ba79c9',\n",
       " u'c9636a4f8be8ed4e2fe0a5764670c3a8a1a4c5a2',\n",
       " u'b72962865bbae183982dab4e3ed8de9a59fb4788']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.saveAsTextFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/UNIQUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniquedataset = sc.textFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'2d0d61cc03f3abd6c5f86087cc92743d3af4d61c,1',\n",
       " u'363ca60eef993a994eb383c820df73553bd1f3a6,2',\n",
       " u'cb16eaaf4b3ab12821a601fddae9bdbd61efddcd,3',\n",
       " u'8e3099e948736e15fdcfe7db8a957b3878836c65,4',\n",
       " u'd3d2395652ca7446c2c401411a9c9af28aea9d77,5',\n",
       " u'0ef59c4e157151d6468cedfa85a68e1a9a8a16dc,6',\n",
       " u'39166b2f99039eb1eba41c9a5e39ec2b422edaa5,7',\n",
       " u'40ef4999c8cb743e6c7624b45e8be057d5ba79c9,8',\n",
       " u'c9636a4f8be8ed4e2fe0a5764670c3a8a1a4c5a2,9',\n",
       " u'b72962865bbae183982dab4e3ed8de9a59fb4788,10']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniquedataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[31] at textFile at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniquedataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_id = uniquedataset.map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'2d0d61cc03f3abd6c5f86087cc92743d3af4d61c', u'1'),\n",
       " (u'363ca60eef993a994eb383c820df73553bd1f3a6', u'2'),\n",
       " (u'cb16eaaf4b3ab12821a601fddae9bdbd61efddcd', u'3'),\n",
       " (u'8e3099e948736e15fdcfe7db8a957b3878836c65', u'4'),\n",
       " (u'd3d2395652ca7446c2c401411a9c9af28aea9d77', u'5'),\n",
       " (u'0ef59c4e157151d6468cedfa85a68e1a9a8a16dc', u'6'),\n",
       " (u'39166b2f99039eb1eba41c9a5e39ec2b422edaa5', u'7'),\n",
       " (u'40ef4999c8cb743e6c7624b45e8be057d5ba79c9', u'8'),\n",
       " (u'c9636a4f8be8ed4e2fe0a5764670c3a8a1a4c5a2', u'9'),\n",
       " (u'b72962865bbae183982dab4e3ed8de9a59fb4788', u'10')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_id.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = dict(sc.textFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/unique.csv').map(lambda line: line.split(\",\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'329890'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['fa40b43298ba3f8aa52e8e8863faf2e2171e0b5d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'3bd73256-3905-4f3a-97e2-8b341527f805',\n",
       "  u'betty blowtorch',\n",
       "  u'2137'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'f2fb0ff0-5679-42ec-a55c-15109ce6e320',\n",
       "  u'die \\xc4rzte',\n",
       "  u'1099'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'b3ae82c2-e60b-4551-a76d-6620f1b456aa',\n",
       "  u'melissa etheridge',\n",
       "  u'897'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'3d6bbeb7-f90e-4d10-b440-e153c0d10b53',\n",
       "  u'elvenking',\n",
       "  u'717'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8',\n",
       "  u'juliette & the licks',\n",
       "  u'706'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'8bfac288-ccc5-448d-9573-c33ea2aa5c30',\n",
       "  u'red hot chili peppers',\n",
       "  u'691'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'6531c8b1-76ea-4141-b270-eb1ac5b41375',\n",
       "  u'magica',\n",
       "  u'545'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'21f3573f-10cf-44b3-aeaa-26cccd8448b5',\n",
       "  u'the black dahlia murder',\n",
       "  u'507'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'c5db90c4-580d-4f33-b364-fbaa5a3a58b5',\n",
       "  u'the murmurs',\n",
       "  u'424'),\n",
       " (u'00000c289a1829a808ac09c00daf10bc3c4e223b',\n",
       "  u'0639533a-0402-40ba-b6e0-18b067198b73',\n",
       "  u'lunachicks',\n",
       "  u'403')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = data1.map(lambda g: (x[g[0]],g[1],g[2],g[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'289263',\n",
       "  u'3bd73256-3905-4f3a-97e2-8b341527f805',\n",
       "  u'betty blowtorch',\n",
       "  u'2137'),\n",
       " (u'289263',\n",
       "  u'f2fb0ff0-5679-42ec-a55c-15109ce6e320',\n",
       "  u'die \\xc4rzte',\n",
       "  u'1099'),\n",
       " (u'289263',\n",
       "  u'b3ae82c2-e60b-4551-a76d-6620f1b456aa',\n",
       "  u'melissa etheridge',\n",
       "  u'897'),\n",
       " (u'289263', u'3d6bbeb7-f90e-4d10-b440-e153c0d10b53', u'elvenking', u'717'),\n",
       " (u'289263',\n",
       "  u'bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8',\n",
       "  u'juliette & the licks',\n",
       "  u'706'),\n",
       " (u'289263',\n",
       "  u'8bfac288-ccc5-448d-9573-c33ea2aa5c30',\n",
       "  u'red hot chili peppers',\n",
       "  u'691'),\n",
       " (u'289263', u'6531c8b1-76ea-4141-b270-eb1ac5b41375', u'magica', u'545'),\n",
       " (u'289263',\n",
       "  u'21f3573f-10cf-44b3-aeaa-26cccd8448b5',\n",
       "  u'the black dahlia murder',\n",
       "  u'507'),\n",
       " (u'289263', u'c5db90c4-580d-4f33-b364-fbaa5a3a58b5', u'the murmurs', u'424'),\n",
       " (u'289263', u'0639533a-0402-40ba-b6e0-18b067198b73', u'lunachicks', u'403')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = data1.map(lambda f: f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = a.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160168"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'',\n",
       " u'ba284f8b-d5a0-4f00-bf79-323eedc976c7',\n",
       " u'0692eaac-1678-4722-83c9-4a4a29f9c202',\n",
       " u'69c4cc43-8163-41c5-ac81-30946d27bb69',\n",
       " u'1961c2dc-bc24-4ed1-bc0a-abdd727dd3bd',\n",
       " u'6bb88fd1-16ca-48e3-8eef-9d03bfd9872c',\n",
       " u'c5023415-17ab-4cca-b6d0-5d18ea4f6d94',\n",
       " u'7ae6592b-885b-4d87-a1a1-ca82f34a4f13',\n",
       " u'caba2357-23c1-4136-ab7e-e5a8256ae1b1',\n",
       " u'5e6b5e5b-c1c5-4224-bab3-38a09d03a8ed']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.saveAsTextFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/unique_artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = data1.filter(lambda x: x[1] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[58] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17333078"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = dict(sc.textFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/unique_artist.csv').map(lambda line: line.split(\",\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['ba284f8b-d5a0-4f00-bf79-323eedc976c7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = data2.map(lambda g: (x[g[0]],z[g[1]],g[2],g[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'289263', u'132018', u'betty blowtorch', u'2137'),\n",
       " (u'289263', u'5759', u'die \\xc4rzte', u'1099'),\n",
       " (u'289263', u'77900', u'melissa etheridge', u'897'),\n",
       " (u'289263', u'128670', u'elvenking', u'717'),\n",
       " (u'289263', u'123524', u'juliette & the licks', u'706'),\n",
       " (u'289263', u'59588', u'red hot chili peppers', u'691'),\n",
       " (u'289263', u'105735', u'magica', u'545'),\n",
       " (u'289263', u'81133', u'the black dahlia murder', u'507'),\n",
       " (u'289263', u'56096', u'the murmurs', u'424'),\n",
       " (u'289263', u'120619', u'lunachicks', u'403'),\n",
       " (u'289263', u'47488', u'walls of jericho', u'393'),\n",
       " (u'289263', u'65261', u'letzte instanz', u'387'),\n",
       " (u'289263', u'111596', u'goldfrapp', u'361'),\n",
       " (u'289263', u'76578', u'horrorpops', u'358'),\n",
       " (u'289263', u'45451', u'the butchies', u'329'),\n",
       " (u'289263', u'126018', u'jack off jill', u'316'),\n",
       " (u'289263', u'72532', u'babes in toyland', u'310'),\n",
       " (u'289263', u'130784', u'dropkick murphys', u'302'),\n",
       " (u'289263', u'17829', u'all:my:faults', u'288'),\n",
       " (u'289263', u'32046', u'le tigre', u'281')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'289263', u'132018', u'betty blowtorch', u'2137'),\n",
       " (u'289263', u'5759', u'die \\xc4rzte', u'1099'),\n",
       " (u'289263', u'77900', u'melissa etheridge', u'897'),\n",
       " (u'289263', u'128670', u'elvenking', u'717'),\n",
       " (u'289263', u'123524', u'juliette & the licks', u'706'),\n",
       " (u'289263', u'59588', u'red hot chili peppers', u'691'),\n",
       " (u'289263', u'105735', u'magica', u'545'),\n",
       " (u'289263', u'81133', u'the black dahlia murder', u'507'),\n",
       " (u'289263', u'56096', u'the murmurs', u'424'),\n",
       " (u'289263', u'120619', u'lunachicks', u'403'),\n",
       " (u'289263', u'47488', u'walls of jericho', u'393'),\n",
       " (u'289263', u'65261', u'letzte instanz', u'387'),\n",
       " (u'289263', u'111596', u'goldfrapp', u'361'),\n",
       " (u'289263', u'76578', u'horrorpops', u'358'),\n",
       " (u'289263', u'45451', u'the butchies', u'329'),\n",
       " (u'289263', u'126018', u'jack off jill', u'316'),\n",
       " (u'289263', u'72532', u'babes in toyland', u'310'),\n",
       " (u'289263', u'130784', u'dropkick murphys', u'302'),\n",
       " (u'289263', u'17829', u'all:my:faults', u'288'),\n",
       " (u'289263', u'32046', u'le tigre', u'281'),\n",
       " (u'289263', u'160030', u'schandmaul', u'244'),\n",
       " (u'289263', u'81', u'edguy', u'232'),\n",
       " (u'289263', u'129763', u'maximum the hormone', u'231'),\n",
       " (u'289263', u'39435', u'all ends', u'229'),\n",
       " (u'289263', u'56034', u'jack johnson', u'227'),\n",
       " (u'289263', u'148470', u'eluveitie', u'222'),\n",
       " (u'289263', u'77940', u'rasputina', u'220'),\n",
       " (u'289263', u'124567', u'london after midnight', u'210'),\n",
       " (u'289263', u'102627', u'the killers', u'208'),\n",
       " (u'289263', u'148090', u'mutyumu', u'205'),\n",
       " (u'289263', u'31934', u'judas priest', u'198'),\n",
       " (u'289263', u'47578', u'rob zombie', u'198'),\n",
       " (u'289263', u'23172', u'the bosshoss', u'189'),\n",
       " (u'289263', u'114890', u'blue \\xd6yster cult', u'185'),\n",
       " (u'289263', u'61685', u'sandra nasic', u'183'),\n",
       " (u'289263', u'131870', u'john mayer', u'182'),\n",
       " (u'289263', u'80136', u'sleater-kinney', u'175'),\n",
       " (u'289263', u'143776', u'the who', u'168'),\n",
       " (u'289263', u'52018', u'disciple', u'154'),\n",
       " (u'289263', u'88001', u'tanzwut', u'153'),\n",
       " (u'289263', u'104072', u'guano apes', u'151'),\n",
       " (u'289263', u'91573', u'the rolling stones', u'150'),\n",
       " (u'289263', u'22421', u'little big town', u'145'),\n",
       " (u'289263', u'44466', u'team dresch', u'137'),\n",
       " (u'289263', u'86739', u'betty', u'135'),\n",
       " (u'289263', u'36371', u'l7', u'135'),\n",
       " (u'289263', u'27259', u'bif naked', u'134'),\n",
       " (u'289263', u'66117', u'girlschool', u'134'),\n",
       " (u'289263', u'135025', u'the wallflowers', u'131'),\n",
       " (u'4417', u'62344', u'the most serene republic', u'12763'),\n",
       " (u'4417', u'26201', u'stars', u'8192'),\n",
       " (u'4417', u'33040', u'broken social scene', u'6413'),\n",
       " (u'4417', u'70132', u'have heart', u'5361'),\n",
       " (u'4417', u'43264', u'luminous orange', u'5120'),\n",
       " (u'4417', u'87882', u'boris', u'5110'),\n",
       " (u'4417', u'62884', u'arctic monkeys', u'4811'),\n",
       " (u'4417', u'141265', u'bright eyes', u'4283'),\n",
       " (u'4417', u'40495', u'coaltar of the deepers', u'4143'),\n",
       " (u'4417', u'76329', u'polar bear club', u'4091'),\n",
       " (u'4417', u'137585', u'the libertines', u'3916'),\n",
       " (u'4417', u'29070', u'death from above 1979', u'3315'),\n",
       " (u'4417', u'65426', u'owl city', u'3147'),\n",
       " (u'4417', u'144280', u'coldplay', u'2658'),\n",
       " (u'4417', u'155057', u'okkervil river', u'2641'),\n",
       " (u'4417', u'126964', u'jim sturgess', u'2427'),\n",
       " (u'4417', u'54128', u'deerhoof', u'2369'),\n",
       " (u'4417', u'149471', u'fear before the march of flames', u'2362'),\n",
       " (u'4417', u'153421', u'breathe carolina', u'2259'),\n",
       " (u'4417', u'139192', u'mstrkrft', u'2102'),\n",
       " (u'4417', u'100412', u'arcade fire', u'1899'),\n",
       " (u'4417', u'7922', u'the strokes', u'1854'),\n",
       " (u'4417', u'147702', u'cancer bats', u'1703'),\n",
       " (u'4417', u'43428', u'the honorary title', u'1682'),\n",
       " (u'4417', u'84125', u'michio kurihara', u'1530'),\n",
       " (u'4417', u'148295', u'mgmt', u'1468'),\n",
       " (u'4417', u'100334', u'queen', u'1404'),\n",
       " (u'4417', u'17694', u'the secret handshake', u'1384'),\n",
       " (u'4417', u'156304', u'animal collective', u'1373'),\n",
       " (u'4417', u'98713', u'heavy heavy low low', u'1323'),\n",
       " (u'4417', u'158726', u'hot hot heat', u'1312'),\n",
       " (u'4417', u'44474', u'hadouken!', u'1254'),\n",
       " (u'4417', u'10828', u'the wombats', u'1244'),\n",
       " (u'4417', u'108400', u'ai aso', u'1232'),\n",
       " (u'4417', u'16830', u'boris with michio kurihara', u'1034'),\n",
       " (u'4417', u'122899', u'uffie', u'977'),\n",
       " (u'4417', u'26218', u'the last shadow puppets', u'961'),\n",
       " (u'4417', u'58337', u'boys noize', u'748'),\n",
       " (u'4417', u'18815', u'built to spill', u'731'),\n",
       " (u'4417', u'126528', u'nujabes', u'707'),\n",
       " (u'4417', u'56518', u'the rocket summer', u'691'),\n",
       " (u'4417', u'122497', u'little dragon', u'672'),\n",
       " (u'4417', u'12263', u'boris with merzbow', u'636'),\n",
       " (u'4417', u'32338', u'the album leaf', u'622'),\n",
       " (u'4417', u'122525', u'the microphones', u'606'),\n",
       " (u'4417', u'71856', u'simian mobile disco', u'603'),\n",
       " (u'4417', u'10198', u'm.i.a.', u'589'),\n",
       " (u'4417', u'33560', u'death cab for cutie', u'587'),\n",
       " (u'4417', u'119654', u'patrick wolf', u'564'),\n",
       " (u'4417', u'142561', u'the fiery furnaces', u'543'),\n",
       " (u'4417', u'105746', u'digitalism', u'505')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = c.filter(lambda x: x[2] == 'digitalism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'4417', u'105746', u'digitalism', u'505'),\n",
       " (u'92454', u'105746', u'digitalism', u'387'),\n",
       " (u'251343', u'105746', u'digitalism', u'6'),\n",
       " (u'117425', u'105746', u'digitalism', u'193'),\n",
       " (u'39606', u'105746', u'digitalism', u'22'),\n",
       " (u'33894', u'105746', u'digitalism', u'229'),\n",
       " (u'356567', u'105746', u'digitalism', u'41'),\n",
       " (u'317832', u'105746', u'digitalism', u'729'),\n",
       " (u'101821', u'105746', u'digitalism', u'267'),\n",
       " (u'166554', u'105746', u'digitalism', u'382')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o543.saveAsTextFile.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 6, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/serializers.py\", line 133, in dump_stream\n    for obj in iterator:\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.py\", line 1462, in func\n    for x in iterator:\n  File \"<ipython-input-107-8756534ec647>\", line 1, in <lambda>\nKeyError: u''\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.next(PythonRDD.scala:101)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.next(PythonRDD.scala:97)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:43)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply$mcV$sp(PairRDDFunctions.scala:1109)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1285)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-7686f0458222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/temp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[0;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;31m# Pair functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o543.saveAsTextFile.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 6, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/lib/pyspark.zip/pyspark/serializers.py\", line 133, in dump_stream\n    for obj in iterator:\n  File \"/Users/bapiakula/Documents/Spark/spark-1.4.0/python/pyspark/rdd.py\", line 1462, in func\n    for x in iterator:\n  File \"<ipython-input-107-8756534ec647>\", line 1, in <lambda>\nKeyError: u''\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.next(PythonRDD.scala:101)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.next(PythonRDD.scala:97)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:43)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply$mcV$sp(PairRDDFunctions.scala:1109)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1285)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1266)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1257)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1256)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1256)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1411)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n"
     ]
    }
   ],
   "source": [
    "d.saveAsTextFile('/Users/bapiakula/Documents/music_recomm/lastfm-dataset-360k/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
